{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from saga import SAGA\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR,LambdaLR\n",
    "from helpers import *\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MOMENTUM_SAGA = 0.1\n",
    "MOMENTUM_SGD = 0.9\n",
    "betas = (0.9,0.999)\n",
    "N_SAMPLES = 0 #set to 0 to use all dataset\n",
    "n_channels = 1 # 1 to flatten cifar10\n",
    "sched_step = 10000 #for step scheduler\n",
    "gamma = 0.1 #for step scheduler\n",
    "weight_decay = 0.001\n",
    "data = \"mnist\" #\"mnist\" or \"cifar10\"\n",
    "X,y,X_test,y_test,IN_DIM,OUT_DIM = get_data(data,n_channels,N_SAMPLES)\n",
    "model_str = \"LR\"\n",
    "opti = \"Adam\"\n",
    "lr = 0.00001\n",
    "n_epochs = 1000\n",
    "centered = \"uncentered\"\n",
    "if (centered == \"centered\"):\n",
    "    X = (X/127.5) - 1\n",
    "else:\n",
    "    X = X/255\n",
    "\n",
    "if (N_SAMPLES == 0):\n",
    "    N_SAMPLES = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.mean())\n",
    "print(X.min())\n",
    "print(X.max())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_proba = get_class_proba(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self,IN_DIM,OUT_DIM):\n",
    "        super(LR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(IN_DIM, OUT_DIM)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "        nn.Linear(in_dim,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100,out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (model_str == 'LR'):\n",
    "    model = LR\n",
    "else:\n",
    "    model = NN\n",
    "\n",
    "model_GD = model(IN_DIM,OUT_DIM).to(device)\n",
    "model_SGD = model(IN_DIM,OUT_DIM).to(device)\n",
    "model_SAGA_pc1 = model(IN_DIM,OUT_DIM).to(device)\n",
    "\n",
    "model_GD_losses = []\n",
    "model_SGD_losses = []\n",
    "model_SAGA_pc1_losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if (opti == \"Adam\"):\n",
    "    optimizer_GD = torch.optim.Adam(model_GD.parameters(), lr = lr,betas = betas,weight_decay = weight_decay)\n",
    "    optimizer_SGD = torch.optim.Adam(model_SGD.parameters(), lr = lr,betas = betas,weight_decay = weight_decay)\n",
    "    optimizer_SAGA_pc1 = SAGA(model_SAGA_pc1.parameters(),\n",
    "                               n_classes=OUT_DIM, lr = lr,\n",
    "                          class_proba = class_proba,momentum=MOMENTUM_SAGA,compute_var = True, betas = betas,\n",
    "                             use_adam = True,weight_decay = weight_decay)       \n",
    "else:\n",
    "    optimizer_GD = torch.optim.SGD(model_GD.parameters(), lr = lr,weight_decay = weight_decay)\n",
    "    optimizer_SGD = torch.optim.SGD(model_SGD.parameters(), lr = lr,weight_decay = weight_decay)\n",
    "    optimizer_SAGA_pc1 = SAGA(model_SAGA_pc1.parameters(),\n",
    "                              n_classes=OUT_DIM, lr = lr,\n",
    "                              class_proba = None,momentum=MOMENTUM_SAGA,compute_var = True,\n",
    "                            weight_decay = weight_decay)\n",
    "\n",
    "lr_lambda = lambda epoch : 1/np.sqrt(epoch+1)\n",
    "scheduler_SGD = LambdaLR(optimizer_SGD, lr_lambda = lr_lambda)\n",
    "scheduler_SAGA_pc1 = LambdaLR(optimizer_SAGA_pc1, lr_lambda = lr_lambda)\n",
    "        \n",
    "# different scheduling        \n",
    "# scheduler_GD = StepLR(optimizer_GD, step_size=sched_step, gamma=gamma)\n",
    "# scheduler_SGD_MB = StepLR(optimizer_SGD_MB, step_size=sched_step, gamma=gamma)\n",
    "# scheduler_SGD = StepLR(optimizer_SGD, step_size=sched_step, gamma=gamma)\n",
    "# scheduler_SAGA_pc1 = StepLR(optimizer_SAGA_pc1, step_size=sched_step, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train GD\n",
    "tstart = time.process_time()\n",
    "GD_avg_var = []\n",
    "GD_var = 0\n",
    "# for epoch in range(n_epochs):\n",
    "#     inputs = torch.from_numpy(X).to(device)\n",
    "#     labels = torch.tensor(y, dtype=torch.long).to(device)\n",
    "#     outputs = model_GD.forward(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     for param_group in list(model_GD.parameters()):\n",
    "#         GD_var += (param_group.grad.data**2).sum()\n",
    "#     optimizer_GD.step()\n",
    "#     GD_avg_var.append(GD_var.cpu().numpy()/(epoch+1))\n",
    "#     model_GD_losses.append(loss.data.item()) #true loss, not running average\n",
    "#     optimizer_GD.zero_grad()\n",
    "print('GD Elapsed time: {:.2f}s'.format(time.process_time() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train SGD\n",
    "tstart = time.process_time()\n",
    "SGD_avg_var = []\n",
    "SGD_var = 0\n",
    "total_loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    idx = np.random.randint(X.shape[0])\n",
    "    inputs = torch.from_numpy(X)[idx].to(device)\n",
    "    labels = torch.tensor(y, dtype=torch.long)[idx].view(1).to(device)\n",
    "    outputs = model_SGD.forward(inputs).view(1,-1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    total_loss += loss.data.item()\n",
    "    model_SGD_losses.append(total_loss/(epoch+1))\n",
    "    for param_group in list(model_SGD.parameters()):\n",
    "        SGD_var += (param_group.grad.data**2).sum()\n",
    "    SGD_avg_var.append(SGD_var/(epoch+1))\n",
    "    optimizer_SGD.step()\n",
    "    optimizer_SGD.zero_grad()\n",
    "    if (epoch != 0 and (epoch % N_SAMPLES) == 0):\n",
    "        scheduler_SGD.step()\n",
    "print('SGD Elapsed time: {:.2f}s'.format(time.process_time() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train SAGApc1\n",
    "tstart = time.process_time()\n",
    "SAGA_pc1_avg_var = []\n",
    "SAGA_pc1_var = 0\n",
    "total_loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    idx = np.random.randint(X.shape[0])\n",
    "    inputs = torch.from_numpy(X)[idx].to(device)\n",
    "    labels = torch.tensor(y, dtype=torch.long)[idx].view(1).to(device)\n",
    "    label = int(labels.item())\n",
    "    outputs = model_SAGA_pc1.forward(inputs).view(1,-1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    total_loss += loss.data.item()\n",
    "    model_SAGA_pc1_losses.append(total_loss/(epoch+1))\n",
    "    _, var = optimizer_SAGA_pc1.step(idx = label)\n",
    "    SAGA_pc1_var += var\n",
    "    SAGA_pc1_avg_var.append(SAGA_pc1_var/(epoch+1))\n",
    "    optimizer_SAGA_pc1.zero_grad()\n",
    "    if (epoch != 0 and (epoch % N_SAMPLES) == 0):\n",
    "          scheduler_SAGA_pc1.step()\n",
    "print('SAGApc1 Elapsed time: {:.2f}s'.format(time.process_time() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot with hyperparam information\n",
    "def plot_val(losses, labels, value = \"Loss\"):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for loss, label in zip(losses, labels):\n",
    "        if len(loss) != 0:\n",
    "            print(label,loss[-1])\n",
    "        plt.plot(loss, label = label)\n",
    "    plt.legend(loc='upper right')\n",
    "    if (N_SAMPLES == 0):\n",
    "        n_s = \"all\"\n",
    "    else:\n",
    "        n_s = N_SAMPLES\n",
    "    plt.title('{} {} {} training {} SAGA ({} {}) (lr: {}, weight decay: {}, n_samples = {})'.format(model_str,\n",
    "                    data,centered,value,opti,betas,lr,weight_decay, n_s))\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel(value)\n",
    "    #plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_val([model_SGD_losses,\n",
    "          model_SAGA_pc1_losses],\n",
    "         ['SGD', \n",
    "         'SAGApc1 (gradient momentum : {})'.format(MOMENTUM_SAGA)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot variance without hyperparam info\n",
    "def plot_val(losses, labels,val = \"Variance\"):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for loss, label in zip(losses, labels):\n",
    "        plt.plot(loss, label = label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Iteration',fontsize = 25)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.ylabel(val,fontsize = 25)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_val([SGD_avg_var,SAGA_pc1_avg_var],\n",
    "         ['SGD', \n",
    "         'SAGApc(1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
